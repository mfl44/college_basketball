{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code does the following:\n",
    "\n",
    "#### 1) Access SportsReference website to pull college team names\n",
    "#### 2) Convert these team names to usable addresses to access the logos on the local drive (.png files)\n",
    "#### 3) Open all logo files, resize images for speed of processing, using computer vision to determine the color of each pixel on file (ignoring the full spectrum of \"white\" colors, which would otherwise be the dominant color in all images\n",
    "#### 4) Determine what the dominant color in each image is for future use in color coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "#establish variables for list/DB objects\n",
    "name = []\n",
    "School_list = []\n",
    "Add_list = [] #list of web address versions of school names\n",
    "Src_DB = [] #dataframe to store school names and their corresponding web address names\n",
    "Rmv_Char = ['.', '(', ')', '&'] #characters to remove from school names\n",
    "Clr_List = [] #list of colors\n",
    "\n",
    "#establish variable for HTML address\n",
    "sref = 'https://www.sports-reference.com/cbb/seasons/2017-school-stats.html'\n",
    "\n",
    "#Parse School Names from Basic Season Stats page\n",
    "r = requests.get(sref) #access html address\n",
    "soup = BeautifulSoup(r.content, \"lxml\") #access content of html address\n",
    "t = soup.find(\"table\", id = \"basic_school_stats\") #find appropriate table on page\n",
    "\n",
    "for i in t.find_all(\"tr\")[:]: #find all table rows\n",
    "    name = [a.get_text().encode('utf-8') for a in i.find_all(\"a\")]\n",
    "    for name in name:\n",
    "        School_list.append(name)\n",
    "        name = name.translate(None, ''.join(Rmv_Char)).replace(\"'\", \"\").replace(\" \", \"-\")\n",
    "        Add_list.append(name.lower())\n",
    "\n",
    "#exception handling to re-write school names that do not match off with the address for the .png file        \n",
    "for p in range(0, len(Add_list)-1):\n",
    "    if Add_list[p] == 'siu-edwardsville':\n",
    "        Add_list[p] = 'southern-illinois-edwardsville'\n",
    "    elif Add_list[p] == 'texas-rio-grande-valley':\n",
    "        Add_list[p] = 'texas-pan-american'\n",
    "    elif Add_list[p] == 'uc-davis':\n",
    "        Add_list[p] = 'california-davis'\n",
    "    elif Add_list[p] == 'uc-irvine':\n",
    "        Add_list[p] = 'california-irvine'\n",
    "    elif Add_list[p] == 'uc-riverside':\n",
    "        Add_list[p] = 'california-riverside'\n",
    "    elif Add_list[p] == 'uc-santa-barbara':\n",
    "        Add_list[p] = 'california-santa-barbara'\n",
    "    elif Add_list[p] == 'university-of-california':\n",
    "        Add_list[p] = 'california'\n",
    "    elif Add_list[p] == 'vmi':\n",
    "        Add_list[p] = 'virginia-military-institute'\n",
    "    elif Add_list[p] == 'william--mary':\n",
    "        Add_list[p] = 'william-mary'\n",
    "    \n",
    "Src_DB = pd.DataFrame(\n",
    "    {'SCHOOL_(SREF)': School_list,\n",
    "     'Src': Add_list\n",
    "    })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = 'C:\\\\Users\\\\E&M\\\\Pictures\\\\Team_Logos\\\\' #address for team logos on local drive\n",
    "f = '.png'\n",
    "addr_lst = [] #second list of address names (local)\n",
    "for s in range(0, len(Add_list)):\n",
    "    addr = q + Add_list[s] + f\n",
    "    addr_lst.append(addr)\n",
    "    \n",
    "Src_DB['Address'] = addr_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reduce size of img to speed up processing; pull BGR value of each pixel\n",
    "clr_list = []\n",
    "a_list = []\n",
    "for a in addr_lst:\n",
    "    img = cv2.imread(a, cv2.IMREAD_COLOR)\n",
    "    img.resize(75,75,3)\n",
    "    h, w, d = img.shape\n",
    "    for y in range(0, h):\n",
    "        for x in range(0,w):\n",
    "            pxl = img[x,y]\n",
    "            if ((pxl[0] >= 170) and (pxl[1] >= 170) and (pxl[2] >= 170)):\n",
    "                pass\n",
    "            else:\n",
    "                a_list.append(a)\n",
    "                clr_list.append(str(pxl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seattle and Texas Pan American aren't pulling into the DF for some reason; doing thest two seperately until determining issue\n",
    "img = cv2.imread('C:\\Users\\E&M\\Pictures\\Team_Logos\\seattle.png', cv2.IMREAD_COLOR)\n",
    "h,w,d = img.shape\n",
    "for y in range(0,h):\n",
    "    for x in range(0,w):\n",
    "        pxl = img[x,y]\n",
    "        if ((pxl[0] >= 170) and (pxl[1] >= 170) and (pxl[2] >= 170)):\n",
    "            pass\n",
    "        else:\n",
    "            a_list.append('C:\\Users\\E&M\\Pictures\\Team_Logos\\seattle.png')\n",
    "            clr_list.append(str(pxl))\n",
    "\n",
    "img = cv2.imread('C:\\\\Users\\\\E&M\\\\Pictures\\\\Team_Logos\\\\texas-pan-american.png', cv2.IMREAD_COLOR)\n",
    "h,w,d = img.shape\n",
    "for y in range(0,h):\n",
    "    for x in range(0,w):\n",
    "        pxl = img[x,y]\n",
    "        if ((pxl[0] >= 170) and (pxl[1] >= 170) and (pxl[2] >= 170)):\n",
    "            pass\n",
    "        else:\n",
    "            a_list.append('C:\\Users\\E&M\\Pictures\\Team_Logos\\texas-pan-american.png')\n",
    "            clr_list.append(str(pxl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataframe to store list of colors and their corresponding team\n",
    "clr_DF = pd.DataFrame({\n",
    "    'Address': a_list,\n",
    "    'Color_(BGR)': clr_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#determine dominant color for each team by grouping\n",
    "clr_DF = clr_DF.groupby(['Address']).agg(lambda x:x.value_counts().index[0])\n",
    "clr_DF.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create DF with all necessary color data and save to local drive\n",
    "Full_Clr_DB = pd.merge(Src_DB, clr_DF, how='left', on='Address')\n",
    "Full_Clr_DB['SCHOOL_(ESPN)'] = Full_Clr_DB['SCHOOL_(SREF)'].map(name_dict)\n",
    "Full_Clr_DB.to_csv('Full_Clr_DB.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
