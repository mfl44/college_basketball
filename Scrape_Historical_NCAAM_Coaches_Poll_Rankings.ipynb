{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The purpose of this code is to pull all the necessary data to show performance of each team, using the coaches' poll point system, over time, ultimately showing which teams have been the best since 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "#establish variable for DB object\n",
    "CoachesPoll_DB = []\n",
    "\n",
    "#establish variable for HTML address\n",
    "espn = 'http://www.espn.com/mens-college-basketball/rankings/_/poll/2/year/'\n",
    "\n",
    "#parse the titles of the USA Today Coaches Poll Rankings \n",
    "#table from the first Rankings page\n",
    "u = espn + str('2003/week/1/seasontype/2')\n",
    "r = requests.get(u)\n",
    "\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "tbl = soup.find(\"div\", id = \"my-teams-table\")\n",
    "\n",
    "#pull headers from USA Today Coaches Poll Rankings Table\n",
    "for i in tbl.find_all(\"tr\")[1:2]:\n",
    "    head = [td.get_text().encode('utf-8') for td in i.find_all(\"td\")]\n",
    "    head = head[1:]\n",
    "    head.extend(['YEAR', 'WEEK', 'SEASON'])\n",
    "    CoachesPoll_DB.append(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#establish variable for current year\n",
    "\n",
    "cur_yr = datetime.now().year\n",
    "\n",
    "#Loop through all years from 2003 to present, all season types, and all weeks\n",
    "#to pull data\n",
    "for y in range (2003, cur_yr + 1):\n",
    "    for q in range (1, 4):\n",
    "        for x in range (1,21):\n",
    "            l = espn + str(y) + '/week/' + str(x) + '/seasontype/' + str(q)\n",
    "            h = requests.get(l)\n",
    "            soup2 = BeautifulSoup(h.content, \"lxml\")\n",
    "            t = soup2.find(\"div\", id = \"my-teams-table\")\n",
    "            for z in t.find_all(\"tr\")[2:]:\n",
    "                team_rank = [li.get_text().encode('utf-8') for li in z.find_all(\"li\")]\n",
    "                team_y = str(y)\n",
    "                team_w = str(x)\n",
    "                #Season Type == 2 --> Regular Season \n",
    "                if q == 2:\n",
    "                    team_rank = team_rank + [team_y] + [team_w] + ['Regular Season']\n",
    "                    CoachesPoll_DB.append(team_rank)\n",
    "                #Season Type != 2 --> Postseason\n",
    "                else:\n",
    "                    team_rank = team_rank + [team_y] + [team_w] + ['Postseason']\n",
    "                    CoachesPoll_DB.append(team_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting list of lists to pandas dataframe\n",
    "df = pd.DataFrame(CoachesPoll_DB[:],columns=CoachesPoll_DB[0])\n",
    "df = df[1:]\n",
    "#clean data by deleting all None from table; reindex table\n",
    "df = df[pd.notnull(df['YEAR'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop all 1st place votes from team names\n",
    "df['TEAM'] = (df['TEAM'].map(lambda f: f.split(' (', 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating Week_ID column to for future use in joining original DataFrame to a DataFrame storing unique identifying values\n",
    "df['Week_ID'] = df['YEAR'] + ' ' + df['SEASON'] + ' Week ' + df['WEEK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pulling all unique identifying values for each week of each year through present\n",
    "wk_idx = pd.unique(df['Week_ID'].values.ravel())\n",
    "wk_idx = pd.Series(np.arange(len(wk_idx)), wk_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a second dataframe to more easily join the Week ID and Week Index to the original DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'Week_ID':wk_idx.index,\n",
    "    'Week_Index': wk_idx.values\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CP_df = pd.merge(df, df2, how='left', on='Week_ID') #join the two databases based on the Week_ID value\n",
    "CP_df['PTS'] = CP_df['PTS'].astype(int) #convert the pts column from text to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing unnecessary/unwanted columns\n",
    "del CP_df['RECORD']\n",
    "del CP_df['PREV']\n",
    "del CP_df['TRENDING']\n",
    "del CP_df['YEAR']\n",
    "del CP_df['WEEK']\n",
    "del CP_df['SEASON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create index column for easier reference in future\n",
    "CP_df['Week_&_Team_Index'] = CP_df['Week_Index'].astype(str) + ' ' + CP_df['TEAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dataframe containing team, week #, and coaches' poll point data\n",
    "k_list = list(name_dict.keys())\n",
    "tempt_list = [] #temporary team list\n",
    "tempi_list = [] #temporary index list\n",
    "pts_list = [] #list containing coaches' poll points\n",
    "wkid_list = [] #week id list\n",
    "\n",
    "for ti in range(0, len(k_list)-1):\n",
    "    for num in range(0, CP_df['Week_Index'].max()+1):\n",
    "        tempt_list.append(k_list[ti])\n",
    "        tempi_list.append(num)\n",
    "        pts_list.append('0')\n",
    "        wkid_list.append('')\n",
    "df3 = pd.DataFrame({\n",
    "    'TEAM': tempt_list,\n",
    "    'PTS': pts_list,\n",
    "    'Week_ID': wkid_list,\n",
    "    'Week_Index': tempi_list,\n",
    "})\n",
    "df3 = df3[['TEAM', 'PTS', 'Week_ID', 'Week_Index']]\n",
    "df3['Week_&_Team_Index'] = df3['Week_Index'].astype(str) + ' ' + df3['TEAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_on = df3[~df3['Week_&_Team_Index'].isin(CP_df['Week_&_Team_Index'])]\n",
    "temp_frame = [CP_df, add_on]\n",
    "Total_CP_Pts_DF = pd.concat(temp_frame)\n",
    "Total_CP_Pts_DF['PTS'] = Total_CP_Pts_DF['PTS'].astype(int)\n",
    "Sorted_CP_df = Total_CP_Pts_DF.sort_values('Week_Index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sorted_CP_df['Cumulative_Points'] = Sorted_CP_df['PTS'].groupby(Sorted_CP_df['TEAM']).cumsum()\n",
    "del Sorted_CP_df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({\n",
    "    'Week_ID': df2['Week_ID'],\n",
    "    'Week_Index': df2['Week_Index']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dominant color list\n",
    "team_df = pd.DataFrame.from_csv('C:\\Users\\E&M\\Downloads\\Full_Clr_DB.csv')\n",
    "#reformat BGR column to separate\n",
    "team_df['Color_(BGR)'] = team_df['Color_(BGR)'].str.replace(']','').str.replace('[','')\n",
    "#create separate columns for B G & R values\n",
    "team_df = team_df.join(pd.DataFrame(team_df['Color_(BGR)'].astype(str).str.split().tolist(),columns=['B', 'G', 'R']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output : \n",
    "df4.to_csv('week_index.csv')\n",
    "Sorted_CP_df.to_csv('sortedcpdf.csv')\n",
    "team_df.to_csv('team_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
